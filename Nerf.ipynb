{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports needed to load the data, train the model, and plot its performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from PIL import Image\n",
    "import imageio \n",
    "from torchvision import datasets, transforms, utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data to train the network: Code was adapted from the official NeRF repository to work with PyTorch. https://github.com/bmild/nerf/blob/master/load_blender.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_t = lambda t : torch.tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,t],\n",
    "    [0,0,0,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "rot_phi = lambda phi : torch.tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,torch.cos(phi),-torch.sin(phi),0],\n",
    "    [0,torch.sin(phi), torch.cos(phi),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "rot_theta = lambda th : torch.tensor([\n",
    "    [torch.cos(th),0,-torch.sin(th),0],\n",
    "    [0,1,0,0],\n",
    "    [torch.sin(th),0, torch.cos(th),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=torch.float32)\n",
    "\n",
    "\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(torch.tensor(radius))\n",
    "    c2w = rot_phi(torch.tensor(phi/180.*np.pi)) @ c2w\n",
    "    c2w = rot_theta(torch.tensor((theta/180.*np.pi))) @ c2w\n",
    "    c2w = np.array([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]]) @ c2w\n",
    "    return c2w\n",
    "    \n",
    "\n",
    "\n",
    "def load_blender_data(basedir, half_res=False, testskip=1):\n",
    "    splits = ['train', 'val', 'test']\n",
    "    metas = {}\n",
    "    for s in splits:\n",
    "        with open(os.path.join(basedir, 'transforms_{}.json'.format(s)), 'r') as fp:\n",
    "            metas[s] = json.load(fp)\n",
    "\n",
    "    all_imgs = []\n",
    "    all_poses = []\n",
    "    counts = [0]\n",
    "    for s in splits:\n",
    "        meta = metas[s]\n",
    "        imgs = []\n",
    "        poses = []\n",
    "        if s=='train' or testskip==0:\n",
    "            skip = 1\n",
    "        else:\n",
    "            skip = testskip\n",
    "            \n",
    "        for frame in meta['frames'][::skip]:\n",
    "            fname = os.path.join(basedir, frame['file_path'] + '.png')\n",
    "            imgs.append(imageio.imread(fname))\n",
    "            poses.append(np.array(frame['transform_matrix']))\n",
    "        imgs = (np.array(imgs) / 255.).astype(np.float32) # keep all 4 channels (RGBA)\n",
    "        poses = np.array(poses).astype(np.float32)\n",
    "        counts.append(counts[-1] + imgs.shape[0])\n",
    "        all_imgs.append(imgs)\n",
    "        all_poses.append(poses)\n",
    "    \n",
    "    i_split = [np.arange(counts[i], counts[i+1]) for i in range(3)]\n",
    "    \n",
    "    imgs = np.concatenate(all_imgs, 0)\n",
    "    poses = np.concatenate(all_poses, 0)\n",
    "    \n",
    "    H, W = imgs[0].shape[:2]\n",
    "    camera_angle_x = float(meta['camera_angle_x'])\n",
    "    focal = .5 * W / np.tan(.5 * camera_angle_x)\n",
    "    \n",
    "    render_poses = torch.stack([pose_spherical(angle, -30.0, 4.0) for angle in np.linspace(-180,180,40+1)[:-1]],0)\n",
    "    \n",
    "    if half_res:\n",
    "        imgs = torch.image.resize_area(imgs, [400, 400]).numpy()\n",
    "        H = H//2\n",
    "        W = W//2\n",
    "        focal = focal/2.\n",
    "        \n",
    "    return imgs, poses, render_poses, [H, W, focal], i_split\n",
    "\n",
    "synthetic_data = load_blender_data('data/nerf_synthetic/lego')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the NeRF neural network as defined in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeRF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_position = 60\n",
    "        input_direction = 24\n",
    "        output_density = 1\n",
    "        output_colour = 3\n",
    "        hidden_features = 256\n",
    "\n",
    "        self.l1 = nn.Linear(input_position,  hidden_features)\n",
    "        self.l2 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.l3 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.l4 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.l5 = nn.Linear(hidden_features + input_position, hidden_features)\n",
    "        self.l6 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.l7 = nn.Linear(hidden_features, hidden_features)\n",
    "        self.l8 = nn.Linear(hidden_features, hidden_features)        \n",
    "        self.l9 = nn.Linear(hidden_features+input_direction, hidden_features+output_density)\n",
    "        self.l10 = nn.Linear(hidden_features, 128)\n",
    "        self.l11 = nn.Linear(128, output_colour)\n",
    "\n",
    "        self.activationReLU = nn.ReLU()\n",
    "        self.activationSigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, pos, dir):\n",
    "\n",
    "        h1 = self.activationReLU(self.l1(pos))\n",
    "        h2 = self.activationReLU(self.l2(h1))\n",
    "        h3 = self.activationReLU(self.l3(h2))\n",
    "        h4 = self.activationReLU(self.l4(h3))\n",
    "        h5 = self.activationReLU(self.l5(torch.cat([h4, pos]))) \n",
    "        h6 = self.activationReLU(self.l6(h5))\n",
    "        h7 = self.activationReLU(self.l7(h6))\n",
    "        h8 = self.l8(h7) # no activation function before layer 9\n",
    "        partial_h9 = self.l9(h8)\n",
    "        density = partial_h9[:,0]\n",
    "        h9 = self.activationReLU(torch.cat([partial_h9[:,1:] + dir])) #### cat sur la bonne dimension\n",
    "        h10 = self.activationReLU(self.l10(h9))\n",
    "        colour = self.activationReLU(self.l11(h10))\n",
    "\n",
    "        return density, colour\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a coarse and fine network to start the scene function approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_scene1 = NeRF()\n",
    "coarse_scene1 = NeRF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the encoding function that will take the inputs of the neural network and project them to a higher dimension input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encoding_fct(value,max_dim):\n",
    "    encoded = torch.zeros(max_dim*2)\n",
    "    for i in range(0,max_dim*2, 2):\n",
    "        encoded[i] = torch.sin(torch.pow(torch.Tensor([2]),i)*torch.pi*value)\n",
    "        encoded[i+1] = torch.cos(torch.pow(torch.Tensor([2]),i)*torch.pi*value)\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO : Define Hierarchical volume sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_volume_sampling(nb_coarse_samples,nb_fine_samples,coarse_net,fine_net,min_dist,max_dist, origin,direction):\n",
    "    \n",
    "    for i in range(nb_coarse_samples):\n",
    "        # equidistant samples\n",
    "\n",
    "        for j in range(nb_fine_samples):\n",
    "            # samples randomly taken from a probability law made from the coarse samples weights\n",
    "\n",
    "    return colour"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3656675e5c9ddbad44bbaefbc4c978fb0abed373f282a0307983d4ade1822146"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('iml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
